{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOU8mToMaPJ8uXICp8tIhlG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Afaq0456/Fake-News/blob/main/Fakenews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujXPsjwO4Qot"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('news_articles.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR6iJLg75Xmz",
        "outputId": "710a9e59-8161-4a0f-8c42-946f2dcb3c65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 author                      published  \\\n",
            "0     Barracuda Brigade  2016-10-26T21:41:00.000+03:00   \n",
            "1  reasoning with facts  2016-10-29T08:47:11.259+03:00   \n",
            "2     Barracuda Brigade  2016-10-31T01:41:49.479+02:00   \n",
            "3                Fed Up  2016-11-01T05:22:00.000+02:00   \n",
            "4                Fed Up  2016-11-01T21:56:00.000+02:00   \n",
            "\n",
            "                                               title  \\\n",
            "0  muslims busted they stole millions in govt ben...   \n",
            "1  re why did attorney general loretta lynch plea...   \n",
            "2  breaking weiner cooperating with fbi on hillar...   \n",
            "3  pin drop speech by father of daughter kidnappe...   \n",
            "4  fantastic trumps  point plan to reform healthc...   \n",
            "\n",
            "                                                text language  \\\n",
            "0  print they should pay all the back all the mon...  english   \n",
            "1  why did attorney general loretta lynch plead t...  english   \n",
            "2  red state  \\nfox news sunday reported this mor...  english   \n",
            "3  email kayla mueller was a prisoner and torture...  english   \n",
            "4  email healthcare reform to make america great ...  english   \n",
            "\n",
            "              site_url                                       main_img_url  \\\n",
            "0  100percentfedup.com  http://bb4sp.com/wp-content/uploads/2016/10/Fu...   \n",
            "1  100percentfedup.com  http://bb4sp.com/wp-content/uploads/2016/10/Fu...   \n",
            "2  100percentfedup.com  http://bb4sp.com/wp-content/uploads/2016/10/Fu...   \n",
            "3  100percentfedup.com  http://100percentfedup.com/wp-content/uploads/...   \n",
            "4  100percentfedup.com  http://100percentfedup.com/wp-content/uploads/...   \n",
            "\n",
            "   type label                            title_without_stopwords  \\\n",
            "0  bias  Real        muslims busted stole millions govt benefits   \n",
            "1  bias  Real         attorney general loretta lynch plead fifth   \n",
            "2  bias  Real  breaking weiner cooperating fbi hillary email ...   \n",
            "3  bias  Real  pin drop speech father daughter kidnapped kill...   \n",
            "4  bias  Real  fantastic trumps point plan reform healthcare ...   \n",
            "\n",
            "                              text_without_stopwords  hasImage  \n",
            "0  print pay back money plus interest entire fami...       1.0  \n",
            "1  attorney general loretta lynch plead fifth bar...       1.0  \n",
            "2  red state fox news sunday reported morning ant...       1.0  \n",
            "3  email kayla mueller prisoner tortured isis cha...       1.0  \n",
            "4  email healthcare reform make america great sin...       1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(df.info())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPYcIHbo5cr0",
        "outputId": "b305cc7c-c0f7-42d2-e61d-9af12a659e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2096 entries, 0 to 2095\n",
            "Data columns (total 12 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   author                   2096 non-null   object \n",
            " 1   published                2096 non-null   object \n",
            " 2   title                    2096 non-null   object \n",
            " 3   text                     2050 non-null   object \n",
            " 4   language                 2095 non-null   object \n",
            " 5   site_url                 2095 non-null   object \n",
            " 6   main_img_url             2095 non-null   object \n",
            " 7   type                     2095 non-null   object \n",
            " 8   label                    2095 non-null   object \n",
            " 9   title_without_stopwords  2094 non-null   object \n",
            " 10  text_without_stopwords   2046 non-null   object \n",
            " 11  hasImage                 2095 non-null   float64\n",
            "dtypes: float64(1), object(11)\n",
            "memory usage: 196.6+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(df.isnull().sum())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SKtqLHK5hcm",
        "outputId": "3c4ed2e3-823b-45c6-b9e2-9049a7923f18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "author                      0\n",
            "published                   0\n",
            "title                       0\n",
            "text                       46\n",
            "language                    1\n",
            "site_url                    1\n",
            "main_img_url                1\n",
            "type                        1\n",
            "label                       1\n",
            "title_without_stopwords     2\n",
            "text_without_stopwords     50\n",
            "hasImage                    1\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(df.describe())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRmQ8Qu35lZT",
        "outputId": "0025d53c-772d-4efe-d5e7-e4f93d992029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          hasImage\n",
            "count  2095.000000\n",
            "mean      0.777088\n",
            "std       0.416299\n",
            "min       0.000000\n",
            "25%       1.000000\n",
            "50%       1.000000\n",
            "75%       1.000000\n",
            "max       1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ],
      "metadata": {
        "id": "a_skgZ4QHl8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Drop rows with missing values in the 'text' column\n",
        "df = df.dropna(subset=['text'])\n",
        "df['title_without_stopwords'] = df['title_without_stopwords'].fillna('')\n",
        "df['text_without_stopwords'] = df['text_without_stopwords'].fillna('')\n",
        "\n",
        "# Confirm that there are no more missing values\n",
        "print(\"\\nAfter handling missing values:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSEyw3ezKTxI",
        "outputId": "f9d4c13a-eb3a-46db-a14b-336486ff1c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "After handling missing values:\n",
            "author                     0\n",
            "published                  0\n",
            "title                      0\n",
            "text                       0\n",
            "language                   0\n",
            "site_url                   0\n",
            "main_img_url               0\n",
            "type                       0\n",
            "label                      0\n",
            "title_without_stopwords    0\n",
            "text_without_stopwords     0\n",
            "hasImage                   0\n",
            "cleaned_text               0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "# Function to perform text preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Text cleaning\n",
        "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub('[^a-zA-Z]', ' ', text)  # Remove special characters and numbers\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespaces\n",
        "\n",
        "    # Tokenization\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Stopword removal\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "    # Normalization and stemming\n",
        "    ps = PorterStemmer()\n",
        "    words = [ps.stem(word.lower()) for word in words]\n",
        "\n",
        "    # Removal of non-textual elements\n",
        "    words = [word for word in words if word.isalpha()]\n",
        "\n",
        "    # Join the processed words back into a cleaned text\n",
        "    cleaned_text = ' '.join(words)\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "# Apply preprocessing to the 'text' column\n",
        "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "# Save the cleaned dataset to a new CSV file\n",
        "df.to_csv('cleaned_news_articles.csv', index=False)\n"
      ],
      "metadata": {
        "id": "ElALxfJ7KdMM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea22305e-69bf-4a8b-c459-44a98c42376f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into features (X) and labels (y)\n",
        "X = df['cleaned_text']\n",
        "y = df['label'].apply(lambda x: 0 if x == 'Real' else 1)\n",
        "\n",
        "# Split the data into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Model 1: k-Nearest Neighbors (kNN)\n",
        "knn_model = KNeighborsClassifier()\n",
        "\n",
        "# Hyperparameter Optimization for kNN\n",
        "knn_param_grid = {'n_neighbors': [3, 5, 7],\n",
        "                  'weights': ['uniform', 'distance']}\n",
        "knn_grid_search = GridSearchCV(knn_model, knn_param_grid, cv=3)\n",
        "knn_grid_search.fit(X_train_tfidf, y_train)\n",
        "best_knn_model = knn_grid_search.best_estimator_\n",
        "\n",
        "# Retrain kNN model with optimized hyperparameters\n",
        "best_knn_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predictions\n",
        "knn_train_preds = best_knn_model.predict(X_train_tfidf)\n",
        "knn_test_preds = best_knn_model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate kNN model\n",
        "print(\"\\nOptimized kNN Accuracy on Training Set:\", accuracy_score(y_train, knn_train_preds))\n",
        "print(\"Optimized kNN Accuracy on Test Set:\", accuracy_score(y_test, knn_test_preds))\n",
        "print(\"\\nOptimized kNN Classification Report on Test Set:\")\n",
        "print(classification_report(y_test, knn_test_preds))\n",
        "\n",
        "# Model 2: Support Vector Machine (SVM)\n",
        "svm_model = SVC()\n",
        "\n",
        "# Hyperparameter Optimization for SVM\n",
        "svm_param_grid = {'C': [0.1, 1, 10],\n",
        "                  'kernel': ['linear', 'rbf']}\n",
        "svm_grid_search = GridSearchCV(svm_model, svm_param_grid, cv=3)\n",
        "svm_grid_search.fit(X_train_tfidf, y_train)\n",
        "best_svm_model = svm_grid_search.best_estimator_\n",
        "\n",
        "# Retrain SVM model with optimized hyperparameters\n",
        "best_svm_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predictions\n",
        "svm_train_preds = best_svm_model.predict(X_train_tfidf)\n",
        "svm_test_preds = best_svm_model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate SVM model\n",
        "print(\"\\nOptimized SVM Accuracy on Training Set:\", accuracy_score(y_train, svm_train_preds))\n",
        "print(\"Optimized SVM Accuracy on Test Set:\", accuracy_score(y_test, svm_test_preds))\n",
        "print(\"\\nOptimized SVM Classification Report on Test Set:\")\n",
        "print(classification_report(y_test, svm_test_preds))\n",
        "\n",
        "# Model 3: Naive Bayes (Multinomial)\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "# Hyperparameter Optimization for Naive Bayes\n",
        "nb_param_grid = {'alpha': [0.1, 0.5, 1.0, 1.5, 2.0]}\n",
        "nb_grid_search = GridSearchCV(nb_model, nb_param_grid, cv=3)\n",
        "nb_grid_search.fit(X_train_tfidf, y_train)\n",
        "best_nb_model = nb_grid_search.best_estimator_\n",
        "\n",
        "# Retrain Naive Bayes model with optimized hyperparameters\n",
        "best_nb_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predictions\n",
        "nb_train_preds = best_nb_model.predict(X_train_tfidf)\n",
        "nb_test_preds = best_nb_model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate Naive Bayes model\n",
        "print(\"\\nOptimized Naive Bayes Accuracy on Training Set:\", accuracy_score(y_train, nb_train_preds))\n",
        "print(\"Optimized Naive Bayes Accuracy on Test Set:\", accuracy_score(y_test, nb_test_preds))\n",
        "print(\"\\nOptimized Naive Bayes Classification Report on Test Set:\")\n",
        "print(classification_report(y_test, nb_test_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNAQE4K1Kpm3",
        "outputId": "56fe7a4c-d16c-4060-8feb-99b9cba6dfa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimized kNN Accuracy on Training Set: 0.9975609756097561\n",
            "Optimized kNN Accuracy on Test Set: 0.6829268292682927\n",
            "\n",
            "Optimized kNN Classification Report on Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.54      0.57       161\n",
            "           1       0.72      0.78      0.75       249\n",
            "\n",
            "    accuracy                           0.68       410\n",
            "   macro avg       0.67      0.66      0.66       410\n",
            "weighted avg       0.68      0.68      0.68       410\n",
            "\n",
            "\n",
            "Optimized SVM Accuracy on Training Set: 0.9353658536585366\n",
            "Optimized SVM Accuracy on Test Set: 0.7414634146341463\n",
            "\n",
            "Optimized SVM Classification Report on Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.53      0.62       161\n",
            "           1       0.74      0.88      0.81       249\n",
            "\n",
            "    accuracy                           0.74       410\n",
            "   macro avg       0.74      0.70      0.71       410\n",
            "weighted avg       0.74      0.74      0.73       410\n",
            "\n",
            "\n",
            "Optimized Naive Bayes Accuracy on Training Set: 0.8810975609756098\n",
            "Optimized Naive Bayes Accuracy on Test Set: 0.7195121951219512\n",
            "\n",
            "Optimized Naive Bayes Classification Report on Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.43      0.55       161\n",
            "           1       0.71      0.90      0.80       249\n",
            "\n",
            "    accuracy                           0.72       410\n",
            "   macro avg       0.73      0.67      0.67       410\n",
            "weighted avg       0.72      0.72      0.70       410\n",
            "\n"
          ]
        }
      ]
    }
  ]
}